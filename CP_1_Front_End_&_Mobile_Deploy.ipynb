{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Efo78cPHnfBr"
      },
      "outputs": [],
      "source": [
        "# Instalações das bibliotecas:\n",
        "\n",
        "#Bibliotecas necessárias para o projeto, como o PyCaret e o SHAP.\n",
        "\n",
        "\n",
        "!pip install pycaret -q\n",
        "\n",
        "!pip install shap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HSbMbTdoF4I"
      },
      "outputs": [],
      "source": [
        "# Importação das bibliotecas:\n",
        "\n",
        "# Bibliotecas necessárias para trabalhar com os dados, visualizações, modelagem e avaliação de desempenho.\n",
        "\n",
        "# Algumas das bibliotecas incluídas são:\n",
        "# Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, Imbalanced-learn (para o SMOTE), Yellowbrick e PyCaret.\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score, roc_curve\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from yellowbrick.classifier import ROCAUC, ConfusionMatrix\n",
        "from pycaret.classification import *\n",
        "import shap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oboMDYOroNEH"
      },
      "outputs": [],
      "source": [
        "# Carregar e limpar os dados:\n",
        "# Definiu a função `load_and_clean_data` para carregar e limpar os dados.\n",
        "# Essa função lê o arquivo CSV e remove algumas colunas irrelevantes e realiza algumas operações de limpeza nos dados, como calcular a idade dos clientes e o tempo de cadastro.\n",
        "\n",
        "\n",
        "def load_and_clean_data(file_path):\n",
        "    df = pd.read_csv(file_path, encoding='utf-8')\n",
        "    df.drop(['ID', 'Z_CostContact', 'Z_Revenue'], axis=1, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    df['Age'] = datetime.now().year - df['Year_Birth']\n",
        "    df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'])\n",
        "    df['Time_Customer'] = (datetime.now().date() - df['Dt_Customer'].dt.date) / timedelta(days=365)\n",
        "    df.drop('Dt_Customer', axis=1, inplace=True)\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMpTw1KIoPpt"
      },
      "outputs": [],
      "source": [
        "# Visualização de EDA:\n",
        "# Definiu a função `eda_visualization` para realizar uma análise exploratória dos dados (Exploratory Data Analysis - EDA).\n",
        "# Nessa função, é criado um pairplot com o Seaborn para visualizar as relações entre as variáveis, com a variável alvo (Response) como hue.\n",
        "\n",
        "\n",
        "def eda_visualization(df):\n",
        "    sns.set(style=\"ticks\", color_codes=True)\n",
        "    sns.pairplot(df, hue=\"Response\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3T-VOaBGoYCe"
      },
      "outputs": [],
      "source": [
        "# Preparação do dataset para Modelagem:\n",
        "# Definiu a função `prepare_data_for_modeling` para preparar os dados para modelagem.\n",
        "# Nessa função, os dados são separados em variáveis independentes (X) e variável alvo (y), as variáveis categóricas são convertidas em:\n",
        "# Variáveis dummy e os dados são divididos em conjuntos de treinamento e teste.\n",
        "\n",
        "\n",
        "def prepare_data_for_modeling(df):\n",
        "    X = df.drop('Response', axis=1)\n",
        "    y = df['Response']\n",
        "    X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "    y_train = y_train.astype('int')\n",
        "    y_test = y_test.astype('int')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Wk-p-qhoZkO"
      },
      "outputs": [],
      "source": [
        "# Modelagem com Scikit-learn:\n",
        "\n",
        "# Definiu a função `train_decision_tree` para treinar um modelo de árvore de decisão utilizando o Scikit-learn.\n",
        "# Esse modelo é treinado no conjunto de treinamento fornecido como entrada para a função.\n",
        "\n",
        "\n",
        "def train_decision_tree(X_train, y_train):\n",
        "    mdl_dt = DecisionTreeClassifier(random_state=42)\n",
        "    mdl_dt.fit(X_train, y_train)\n",
        "    return mdl_dt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzsgKc1ooa_G"
      },
      "outputs": [],
      "source": [
        "# Balanceamento por SMOTE:\n",
        "# Definiu a função `oversample_with_smote` para aplicar a técnica SMOTE de balanceamento de classes no conjunto de treinamento.\n",
        "# Essa função utiliza a biblioteca Imbalanced-learn para realizar o balanceamento.\n",
        "\n",
        "def oversample_with_smote(X_train, y_train):\n",
        "    sm = SMOTE(random_state=42)\n",
        "    X_res, y_res = sm.fit_resample(X_train, y_train)\n",
        "    return X_res, y_res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPxwtQZ3ofM-"
      },
      "outputs": [],
      "source": [
        "# Função para plotar a matriz de confusão:\n",
        "\n",
        "def plot_confusion_matrix(y_test, y_pred):\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F529vN86of-w"
      },
      "outputs": [],
      "source": [
        "# Função para plotar a curva ROC:\n",
        "\n",
        "def plot_roc_curve(X_train, y_train, X_test, y_test):\n",
        "    visualizer = ROCAUC(mdl_dt, classes=[0, 1], micro=False, macro=False)\n",
        "    visualizer.fit(X_train, y_train)\n",
        "    visualizer.score(X_test, y_test)\n",
        "    visualizer.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEmuWFgIof7g"
      },
      "outputs": [],
      "source": [
        "# Modelagem com PyCaret\n",
        "def perform_pycaret_modeling(df):\n",
        "    exp_clf101 = setup(data=df, target='Response', ignore_features=['ID', 'Z_CostContact', 'Z_Revenue'], session_id=42)\n",
        "    best_model = compare_models()\n",
        "    dt = create_model('dt')  # Atribui o modelo a uma variável\n",
        "    interpret_model(dt)   # Interpreta o modelo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpAgPlxiolE9"
      },
      "outputs": [],
      "source": [
        "# Carregar e limpar os dados:\n",
        "\n",
        "df = load_and_clean_data('data.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnwQWzZ6ou29"
      },
      "outputs": [],
      "source": [
        "# Visualização de EDA:\n",
        "\n",
        "eda_visualization(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGCb4Yz0owwk"
      },
      "outputs": [],
      "source": [
        "# Preparação do dataset para Modelagem:\n",
        "\n",
        "X_train, X_test, y_train, y_test = prepare_data_for_modeling(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelagem com PyCaret:\n",
        "\n",
        "perform_pycaret_modeling(df)"
      ],
      "metadata": {
        "id": "WYIVVOpyiL29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelagem com Scikit-learn:\n",
        "\n",
        "mdl_dt = train_decision_tree(X_train, y_train)\n",
        "ypred_dt = mdl_dt.predict(X_test)\n",
        "plot_confusion_matrix(y_test, ypred_dt)\n",
        "plot_roc_curve(X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "lBrciwoJQ-q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8Lml0fzoymc"
      },
      "outputs": [],
      "source": [
        "# Balanceamento por SMOTE:\n",
        "\n",
        "X_res, y_res = oversample_with_smote(X_train, y_train)\n",
        "mdl_dt = train_decision_tree(X_res, y_res)\n",
        "ypred_dt = mdl_dt.predict(X_test)\n",
        "plot_confusion_matrix(y_test, ypred_dt)\n",
        "plot_roc_curve(X_res, y_res, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX60QaKjo0uV"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v67B8_dVhrjg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}